{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:34:47.990158Z",
     "start_time": "2026-01-08T11:34:47.982676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ],
   "id": "5eb603a8123efa6b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:35:00.582460Z",
     "start_time": "2026-01-08T11:35:00.577540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Footer for branding (as per brand rule)\n",
    "FOOTER = \"Model by sadia\""
   ],
   "id": "1d210f126dd69c9e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:36:29.945744Z",
     "start_time": "2026-01-08T11:36:29.937434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 1: Load data (customized for your dataset)\n",
    "def load_data():\n",
    "    data = pd.read_csv(\"E:\\\\dataset\\\\Air_Quality.csv\")  # Update if filename is different\n",
    "    print(\"Data loaded successfully.\")\n",
    "    return data"
   ],
   "id": "65e81cb70f09e759",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:36:34.334117Z",
     "start_time": "2026-01-08T11:36:34.323560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 2: Define preprocessing pipeline\n",
    "# Missing value strategy (documented):\n",
    "# - Numerical features: Impute with mean\n",
    "# - Categorical features: Impute with most frequent\n",
    "# Scaling/Encoding:\n",
    "# - Numerical: StandardScaler\n",
    "# - Categorical: OneHotEncoder (drop='first')\n",
    "def create_preprocessing_pipeline(numerical_cols, categorical_cols):\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocessor"
   ],
   "id": "130fe0b086de882c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:36:38.523270Z",
     "start_time": "2026-01-08T11:36:38.511032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 3: Main function to run the pipeline\n",
    "def run_pipeline():\n",
    "    # Load data\n",
    "    data = load_data()\n",
    "\n",
    "    # Debug: Print columns to confirm\n",
    "    print(\"Columns in dataset:\", data.columns.tolist())\n",
    "\n",
    "    # Define columns (exact match to your dataset)\n",
    "    numerical_cols = ['CO', 'NO2', 'SO2', 'O3', 'PM2.5', 'PM10']  # Pollutant features\n",
    "    categorical_cols = ['City']  # Only City is categorical\n",
    "    target_col = 'AQI'  # Target column\n",
    "    drop_cols = ['Date']  # Drop Date (not a feature)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(columns=drop_cols)\n",
    "\n",
    "    # Features and target\n",
    "    X = data.drop(columns=[target_col])\n",
    "    y = data[target_col]\n",
    "\n",
    "    # Create and apply pipeline\n",
    "    preprocessor = create_preprocessing_pipeline(numerical_cols, categorical_cols)\n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Get new column names after encoding\n",
    "    cat_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "    preprocessed_cols = numerical_cols + list(cat_names)\n",
    "    X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=preprocessed_cols)\n",
    "    X_preprocessed_df[target_col] = y.values  # Add target back\n",
    "\n",
    "    # Split data (80/20, reproducible)\n",
    "    train, test = train_test_split(X_preprocessed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Add footer row\n",
    "    footer_row = pd.DataFrame([[FOOTER] * len(train.columns)], columns=train.columns)\n",
    "    train_with_footer = pd.concat([train, footer_row], ignore_index=True)\n",
    "    test_with_footer = pd.concat([test, footer_row], ignore_index=True)\n",
    "\n",
    "    # Export\n",
    "    train_with_footer.to_csv('cleaned_train.csv', index=False)\n",
    "    test_with_footer.to_csv('cleaned_test.csv', index=False)\n",
    "\n",
    "    print(f\"Pipeline completed successfully! Footer: {FOOTER}\")\n",
    "    print(\"Train shape:\", train.shape)\n",
    "    print(\"Test shape:\", test.shape)\n",
    "    print(\"Cleaned files exported: cleaned_train.csv and cleaned_test.csv\")"
   ],
   "id": "76745f68a7f32bea",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T11:36:43.968478Z",
     "start_time": "2026-01-08T11:36:43.198472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ],
   "id": "6f54f63c0f113078",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Columns in dataset: ['Date', 'City', 'CO', 'NO2', 'SO2', 'O3', 'PM2.5', 'PM10', 'AQI']\n",
      "Pipeline completed successfully! Footer: Model by sadia\n",
      "Train shape: (42048, 12)\n",
      "Test shape: (10512, 12)\n",
      "Cleaned files exported: cleaned_train.csv and cleaned_test.csv\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
